<!DOCTYPE html> 
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MemoLearning K-Means Clustering</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Inter', sans-serif;
      background: linear-gradient(135deg, #f97316 0%, #ea580c 50%, #dc2626 100%);
      color: #111827;
      margin: 0;
      padding: 0;
      min-height: 100vh;
    }
    
    header {
      background: rgba(255, 255, 255, 0.1);
      backdrop-filter: blur(20px);
      color: white;
      padding: 40px 20px;
      text-align: center;
      border-bottom: 1px solid rgba(255, 255, 255, 0.2);
    }
    
    header h1 {
      font-size: 42px;
      margin: 0;
      font-weight: 800;
      text-shadow: 0 2px 20px rgba(0,0,0,0.3);
    }
    
    header p {
      margin-top: 15px;
      font-size: 18px;
      opacity: 0.9;
    }
    
    .back-link {
      display: inline-block;
      margin-top: 25px;
      padding: 12px 24px;
      background: rgba(255, 255, 255, 0.2);
      color: white;
      text-decoration: none;
      border-radius: 50px;
      font-weight: 600;
      backdrop-filter: blur(10px);
      border: 1px solid rgba(255, 255, 255, 0.3);
      transition: all 0.3s ease;
    }
    
    .back-link:hover {
      background: rgba(255, 255, 255, 0.3);
      transform: translateY(-2px);
      box-shadow: 0 10px 25px rgba(0,0,0,0.2);
    }
    
    .container {
      padding: 40px 20px;
      max-width: 1400px;
      margin: auto;
    }
    
    .units-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
      gap: 30px;
      margin-top: 20px;
    }
    
    .unit-card {
      background: rgba(255, 255, 255, 0.95);
      border-radius: 20px;
      padding: 30px;
      box-shadow: 0 15px 35px rgba(0,0,0,0.1);
      backdrop-filter: blur(20px);
      border: 1px solid rgba(255, 255, 255, 0.5);
      transition: all 0.4s ease;
      cursor: pointer;
      position: relative;
      overflow: hidden;
    }
    
    .unit-card::before {
      content: '';
      position: absolute;
      top: 0;
      left: -100%;
      width: 100%;
      height: 100%;
      background: linear-gradient(90deg, transparent, rgba(255,255,255,0.4), transparent);
      transition: left 0.5s;
    }
    
    .unit-card:hover::before {
      left: 100%;
    }
    
    .unit-card:hover {
      transform: translateY(-10px) scale(1.02);
      box-shadow: 0 25px 50px rgba(0,0,0,0.15);
      background: rgba(255, 255, 255, 1);
    }
    
    .unit-header {
      display: flex;
      align-items: center;
      margin-bottom: 20px;
    }
    
    .unit-number {
      background: linear-gradient(135deg, #f97316, #ea580c);
      color: white;
      width: 40px;
      height: 40px;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 800;
      margin-right: 15px;
      box-shadow: 0 4px 15px rgba(249, 115, 22, 0.4);
    }
    
    .unit-title {
      font-size: 24px;
      font-weight: 800;
      color: #1f2937;
      margin: 0;
      flex: 1;
    }
    
    .unit-description {
      color: #6b7280;
      font-size: 16px;
      margin-bottom: 20px;
      line-height: 1.6;
    }
    
    .topics-list {
      list-style: none;
      padding: 0;
      margin: 0;
    }
    
    .topics-list li {
      padding: 8px 0;
      border-bottom: 1px solid #f3f4f6;
      color: #374151;
      position: relative;
      padding-left: 20px;
    }
    
    .topics-list li:before {
      content: 'üéØ';
      position: absolute;
      left: 0;
      font-size: 12px;
    }
    
    .topics-list li:last-child {
      border-bottom: none;
    }
    
    .curriculum-stats {
      background: rgba(255, 255, 255, 0.1);
      backdrop-filter: blur(20px);
      border-radius: 20px;
      padding: 30px;
      margin-bottom: 40px;
      text-align: center;
      color: white;
    }
    
    .stats-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 30px;
      margin-top: 20px;
    }
    
    .stat-item {
      text-align: center;
    }
    
    .stat-number {
      font-size: 36px;
      font-weight: 800;
      display: block;
    }
    
    .stat-label {
      font-size: 14px;
      opacity: 0.8;
      margin-top: 5px;
    }

    .page-container {
      display: none;
      padding: 40px 20px;
      max-width: 1200px;
      margin: auto;
      background: rgba(255, 255, 255, 0.95);
      border-radius: 20px;
      margin-top: 20px;
      box-shadow: 0 15px 35px rgba(0,0,0,0.1);
    }

    .page-container.active {
      display: block;
    }

    .unit-detail-header {
      text-align: center;
      margin-bottom: 40px;
      padding-bottom: 20px;
      border-bottom: 2px solid #e5e7eb;
    }

    .unit-detail-title {
      font-size: 32px;
      font-weight: 800;
      color: #1f2937;
      margin-bottom: 10px;
    }

    .subtopics-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 20px;
    }

    .subtopic-card {
      background: white;
      border: 2px solid #e5e7eb;
      border-radius: 12px;
      padding: 20px;
      transition: all 0.3s ease;
    }

    .subtopic-card:hover {
      border-color: #f97316;
      transform: translateY(-2px);
      box-shadow: 0 8px 25px rgba(0,0,0,0.1);
    }

    .subtopic-title {
      font-size: 18px;
      font-weight: 600;
      color: #ea580c;
      margin-bottom: 10px;
    }

    .back-to-overview {
      background: linear-gradient(135deg, #f97316, #ea580c);
      color: white;
      border: none;
      padding: 12px 24px;
      border-radius: 25px;
      font-weight: 600;
      cursor: pointer;
      margin-bottom: 30px;
      transition: all 0.3s ease;
    }

    .back-to-overview:hover {
      transform: translateY(-2px);
      box-shadow: 0 8px 20px rgba(249, 115, 22, 0.3);
    }

    .code-example {
      background: #f8fafc;
      border: 1px solid #e2e8f0;
      border-radius: 8px;
      padding: 15px;
      margin: 10px 0;
      font-family: 'Courier New', monospace;
      font-size: 14px;
      color: #334155;
    }

    .kmeans-badge {
      display: inline-block;
      background: #fed7aa;
      color: #c2410c;
      padding: 4px 8px;
      border-radius: 12px;
      font-size: 12px;
      font-weight: 600;
      margin: 2px;
    }

    .cluster-box {
      background: #fff7ed;
      border: 1px solid #fed7aa;
      border-radius: 8px;
      padding: 15px;
      margin: 10px 0;
      font-size: 14px;
      color: #c2410c;
    }

    .algorithm-highlight {
      background: #f0f9ff;
      border: 1px solid #bae6fd;
      border-left: 4px solid #0ea5e9;
      border-radius: 8px;
      padding: 15px;
      margin: 10px 0;
      font-size: 14px;
      color: #0c4a6e;
    }

    .centroid-formula {
      background: #fef3c7;
      border: 1px solid #fed7aa;
      border-radius: 8px;
      padding: 15px;
      margin: 10px 0;
      font-family: 'Times New Roman', serif;
      font-size: 16px;
      text-align: center;
      color: #92400e;
    }
  </style>
  <script>
    function showUnitDetail(unitNumber) {
      // Hide overview
      document.getElementById('overview').style.display = 'none';
      
      // Hide all unit detail pages
      const allUnits = document.querySelectorAll('.page-container');
      allUnits.forEach(unit => unit.classList.remove('active'));
      
      // Show selected unit
      const selectedUnit = document.getElementById('unit-' + unitNumber);
      if (selectedUnit) {
        selectedUnit.classList.add('active');
      }
    }

    function showOverview() {
      // Hide all unit detail pages
      const allUnits = document.querySelectorAll('.page-container');
      allUnits.forEach(unit => unit.classList.remove('active'));
      
      // Show overview
      document.getElementById('overview').style.display = 'block';
    }
  </script>
</head>
<body>
  <header>
    <h1>üéØ K-Means Clustering</h1>
    <p>Master centroid-based clustering, optimization, and unsupervised pattern discovery for data grouping</p>
    <a class="back-link" href="#" onclick="alert('This would navigate back to data science courses')">‚Üê Back to Data Science</a>
  </header>

  <div class="container" id="overview">
    <div class="curriculum-stats">
      <h2 style="margin: 0 0 20px 0; font-size: 28px;">K-Means Clustering Curriculum</h2>
      <div class="stats-grid">
        <div class="stat-item">
          <span class="stat-number">10</span>
          <div class="stat-label">Core Units</div>
        </div>
        <div class="stat-item">
          <span class="stat-number">~55</span>
          <div class="stat-label">Key Concepts</div>
        </div>
        <div class="stat-item">
          <span class="stat-number">8+</span>
          <div class="stat-label">Algorithms</div>
        </div>
        <div class="stat-item">
          <span class="stat-number">25+</span>
          <div class="stat-label">Practical Examples</div>
        </div>
      </div>
    </div>

    <div class="units-grid">
      <div class="unit-card" onclick="showUnitDetail(1)">
        <div class="unit-header">
          <div class="unit-number">1</div>
          <h3 class="unit-title">Introduction to Clustering</h3>
        </div>
        <p class="unit-description">Understand clustering fundamentals and how K-means fits into unsupervised learning.</p>
        <ul class="topics-list">
          <li>What is clustering</li>
          <li>Unsupervised learning context</li>
          <li>Types of clustering algorithms</li>
          <li>Clustering applications</li>
          <li>Similarity and distance measures</li>
          <li>Clustering challenges</li>
          <li>Evaluation without labels</li>
          <li>K-means overview</li>
        </ul>
      </div>

      <div class="unit-card" onclick="showUnitDetail(2)">
        <div class="unit-header">
          <div class="unit-number">2</div>
          <h3 class="unit-title">K-Means Algorithm Fundamentals</h3>
        </div>
        <p class="unit-description">Learn the core K-means algorithm and its iterative optimization process.</p>
        <ul class="topics-list">
          <li>Algorithm overview</li>
          <li>Centroid concept</li>
          <li>Assignment step</li>
          <li>Update step</li>
          <li>Convergence criteria</li>
          <li>Iterative process</li>
          <li>Objective function</li>
          <li>Lloyd's algorithm</li>
        </ul>
      </div>

      <div class="unit-card" onclick="showUnitDetail(3)">
        <div class="unit-header">
          <div class="unit-number">3</div>
          <h3 class="unit-title">Distance Metrics and Similarity</h3>
        </div>
        <p class="unit-description">Master different distance measures used in K-means clustering.</p>
        <ul class="topics-list">
          <li>Euclidean distance</li>
          <li>Manhattan distance</li>
          <li>Cosine similarity</li>
          <li>Minkowski distance</li>
          <li>Distance metric properties</li>
          <li>Impact on cluster shape</li>
          <li>Choosing appropriate metrics</li>
          <li>Custom distance functions</li>
        </ul>
      </div>

      <div class="unit-card" onclick="showUnitDetail(4)">
        <div class="unit-header">
          <div class="unit-number">4</div>
          <h3 class="unit-title">Centroid Initialization</h3>
        </div>
        <p class="unit-description">Learn initialization strategies that significantly impact clustering results.</p>
        <ul class="topics-list">
          <li>Random initialization</li>
          <li>K-means++ algorithm</li>
          <li>Forgy initialization</li>
          <li>Random partition method</li>
          <li>Multiple random starts</li>
          <li>Initialization impact</li>
          <li>Avoiding poor local optima</li>
          <li>Best practices</li>
        </ul>
      </div>

      <div class="unit-card" onclick="showUnitDetail(5)">
        <div class="unit-header">
          <div class="unit-number">5</div>
          <h3 class="unit-title">Choosing the Optimal K</h3>
        </div>
        <p class="unit-description">Master techniques for selecting the optimal number of clusters.</p>
        <ul class="topics-list">
          <li>Elbow method</li>
          <li>Silhouette analysis</li>
          <li>Gap statistic</li>
          <li>Information criteria</li>
          <li>Cross-validation approaches</li>
          <li>Domain knowledge integration</li>
          <li>Stability-based methods</li>
          <li>Practical guidelines</li>
        </ul>
      </div>

      <div class="unit-card" onclick="showUnitDetail(6)">
        <div class="unit-header">
          <div class="unit-number">6</div>
          <h3 class="unit-title">K-Means Convergence</h3>
        </div>
        <p class="unit-description">Understand convergence properties and optimization aspects of K-means.</p>
        <ul class="topics-list">
          <li>Convergence guarantees</li>
          <li>Local vs global optima</li>
          <li>Objective function minimization</li>
          <li>Within-cluster sum of squares</li>
          <li>Iteration limits</li>
          <li>Tolerance settings</li>
          <li>Convergence speed</li>
          <li>Computational complexity</li>
        </ul>
      </div>

      <div class="unit-card" onclick="showUnitDetail(7)">
        <div class="unit-header">
          <div class="unit-number">7</div>
          <h3 class="unit-title">K-Means Limitations</h3>
        </div>
        <p class="unit-description">Learn the assumptions and limitations of the K-means algorithm.</p>
        <ul class="topics-list">
          <li>Spherical cluster assumption</li>
          <li>Equal cluster size bias</li>
          <li>Sensitivity to outliers</li>
          <li>Scale sensitivity</li>
          <li>Curse of dimensionality</li>
          <li>Non-convex cluster shapes</li>
          <li>Predetermined K requirement</li>
          <li>Initialization dependency</li>
        </ul>
      </div>

      <div class="unit-card" onclick="showUnitDetail(8)">
        <div class="unit-header">
          <div class="unit-number">8</div>
          <h3 class="unit-title">K-Means Variants</h3>
        </div>
        <p class="unit-description">Explore variations and improvements to the standard K-means algorithm.</p>
        <ul class="topics-list">
          <li>K-means++</li>
          <li>Mini-batch K-means</li>
          <li>Fuzzy C-means</li>
          <li>K-medoids (PAM)</li>
          <li>Kernel K-means</li>
          <li>Bisecting K-means</li>
          <li>Spherical K-means</li>
          <li>Online K-means</li>
        </ul>
      </div>

      <div class="unit-card" onclick="showUnitDetail(9)">
        <div class="unit-header">
          <div class="unit-number">9</div>
          <h3 class="unit-title">Cluster Evaluation</h3>
        </div>
        <p class="unit-description">Learn methods to assess the quality of K-means clustering results.</p>
        <ul class="topics-list">
          <li>Internal validation metrics</li>
          <li>Silhouette coefficient</li>
          <li>Calinski-Harabasz index</li>
          <li>Davies-Bouldin index</li>
          <li>Within-cluster sum of squares</li>
          <li>Between-cluster separation</li>
          <li>Visual assessment techniques</li>
          <li>Stability analysis</li>
        </ul>
      </div>

      <div class="unit-card" onclick="showUnitDetail(10)">
        <div class="unit-header">
          <div class="unit-number">10</div>
          <h3 class="unit-title">Implementation and Applications</h3>
        </div>
        <p class="unit-description">Build K-means from scratch and explore real-world applications.</p>
        <ul class="topics-list">
          <li>NumPy implementation</li>
          <li>Scikit-learn usage</li>
          <li>Performance optimization</li>
          <li>Large dataset handling</li>
          <li>Customer segmentation</li>
          <li>Image compression</li>
          <li>Market research</li>
          <li>Data preprocessing</li>
        </ul>
      </div>
    </div>
  </div>

  <!-- Unit Detail Pages -->
  <div class="page-container" id="unit-1">
    <button class="back-to-overview" onclick="showOverview()">‚Üê Back to Overview</button>
    <div class="unit-detail-header">
      <h1 class="unit-detail-title">Unit 1: Introduction to Clustering</h1>
      <p>Understand clustering fundamentals and how K-means fits into unsupervised learning.</p>
    </div>
    <div class="subtopics-grid">
      <div class="subtopic-card">
        <h3 class="subtopic-title">What is Clustering</h3>
        <p>Learn the fundamental concept of grouping similar data points together without labeled examples.</p>
        <span class="kmeans-badge">Grouping</span>
        <span class="kmeans-badge">Similarity</span>
        <span class="kmeans-badge">Unsupervised</span>
        <div class="cluster-box">
          Clustering is the task of grouping data points such that points in the same group (cluster) are more similar to each other than to points in other groups.
        </div>
      </div>
      <div class="subtopic-card">
        <h3 class="subtopic-title">Types of Clustering Algorithms</h3>
        <p>Explore different approaches to clustering and understand where K-means fits.</p>
        <div class="algorithm-highlight">
          Partitional: K-means, K-medoids - Divide data into non-overlapping clusters<br>
          Hierarchical: Agglomerative, Divisive - Create tree-like cluster structures<br>
          Density-based: DBSCAN, OPTICS - Find clusters based on density regions<br>
          Model-based: Gaussian Mixture Models - Assume underlying probability distributions
        </div>
        <div class="code-example">
          # Overview of clustering algorithm types<br>
          import numpy as np<br>
          from sklearn.datasets import make_blobs<br>
          from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN<br>
          from sklearn.mixture import GaussianMixture<br>
          import matplotlib.pyplot as plt<br>
          <br>
          # Generate sample data<br>
          X, y_true = make_blobs(n_samples=300, centers=4, n_features=2, <br>
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;random_state=42, cluster_std=1.5)<br>
          <br>
          print("=== CLUSTERING ALGORITHM COMPARISON ===")<br>
          <br>
          # K-means (Partitional)<br>
          kmeans = KMeans(n_clusters=4, random_state=42)<br>
          kmeans_labels = kmeans.fit_predict(X)<br>
          print(f"K-means clusters: {len(np.unique(kmeans_labels))}")<br>
          <br>
          # Hierarchical (Agglomerative)<br>
          hierarchical = AgglomerativeClustering(n_clusters=4)<br>
          hierarchical_labels = hierarchical.fit_predict(X)<br>
          print(f"Hierarchical clusters: {len(np.unique(hierarchical_labels))}")<br>
          <br>
          # Density-based (DBSCAN)<br>
          dbscan = DBSCAN(eps=0.8, min_samples=5)<br>
          dbscan_labels = dbscan.fit_predict(X)<br>
          n_dbscan_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)<br>
          print(f"DBSCAN clusters: {n_dbscan_clusters}")<br>
          <br>
          # Model-based (Gaussian Mixture)<br>
          gmm = GaussianMixture(n_components=4, random_state=42)<br>
          gmm_labels = gmm.fit_predict(X)<br>
          print(f"GMM clusters: {len(np.unique(gmm_labels))}")<br>
          <br>
          print("\\n=== ALGORITHM CHARACTERISTICS ===")<br>
          characteristics = {<br>
          &nbsp;&nbsp;"K-means": {<br>
          &nbsp;&nbsp;&nbsp;&nbsp;"Type": "Partitional",<br>
          &nbsp;&nbsp;&nbsp;&nbsp;"Clusters": "Spherical, equal size",<br>
          &nbsp;&nbsp;&nbsp;&nbsp;"K": "Must specify",<br>
          &nbsp;&nbsp;&nbsp;&nbsp;"Complexity": "O(n*k*i*d)"<br>
          &nbsp;&nbsp;},<br>
          &nbsp;&nbsp;"Hierarchical": {<br>
          &nbsp;&nbsp;&nbsp;&nbsp;"Type": "Hierarchical",<br>
          &nbsp;&nbsp;&nbsp;&nbsp;"Clusters": "Any shape",<br>
          &nbsp;&nbsp;&nbsp;&nbsp;"K": "Choose from dendrogram",<br>
          &nbsp;&nbsp;&nbsp;&nbsp;"Complexity": "O(n¬≥)"<br>
          &nbsp;&nbsp;},<br>
          &nbsp;&nbsp;"DBSCAN": {<br>
          &nbsp;&nbsp;&nbsp;&nbsp;"Type": "Density-based",<br>
          &nbsp;&nbsp;&nbsp;&nbsp;"Clusters": "Any shape, handles noise",<br>
          &nbsp;&nbsp;&nbsp;&nbsp;"K": "Automatic",<br>
          &nbsp;&nbsp;&nbsp;&nbsp;"Complexity": "O(n log n)"<br>
          &nbsp;&nbsp;}<br>
          }<br>
          <br>
          for alg, props in characteristics.items():<br>
          &nbsp;&nbsp;print(f"\\n{alg}:")<br>
          &nbsp;&nbsp;for prop, value in props.items():<br>
          &nbsp;&nbsp;&nbsp;&nbsp;print(f"  {prop}: {value}")
        </div>
      </div>
      <div class="subtopic-card">
        <h3 class="subtopic-title">Clustering Applications</h3>
        <p>Discover real-world applications where clustering provides valuable insights.</p>
        <div class="cluster-box">
          Customer Segmentation: Group customers by behavior<br>
          Market Research: Identify consumer preferences<br>
          Image Segmentation: Separate image regions<br>
          Gene Sequencing: Group similar genetic patterns<br>
          Recommendation Systems: Find user/item groups
        </div>
        <div class="code-example">
          # Real-world clustering applications<br>
          import numpy as np<br>
          import pandas as pd<br>
          from sklearn.cluster import KMeans<br>
          from sklearn.preprocessing import StandardScaler<br>
          <br>
          print("=== CUSTOMER SEGMENTATION EXAMPLE ===")<br>
          <br>
          # Simulate customer data<br>
          np.random.seed(42)<br>
          n_customers = 1000<br>
          <br>
          # Customer features<br>
          age = np.random.normal(40, 15, n_customers)<br>
          income = np.random.normal(50000, 20000, n_customers)<br>
          spending_score = np.random.normal(50, 25, n_customers)<br>
          <br>
          # Create customer dataset<br>
          customers = pd.DataFrame({<br>
          &nbsp;&nbsp;'Age': np.clip(age, 18, 80),<br>
          &nbsp;&nbsp;'Income': np.clip(income, 20000, 150000),<br>
          &nbsp;&nbsp;'SpendingScore': np.clip(spending_score, 1, 100)<br>
          })<br>
          <br>
          print("Customer data sample:")<br>
          print(customers.head())<br>
          print(f"\\nDataset shape: {customers.shape}")<br>
          <br>
          # Standardize features<br>
          scaler = StandardScaler()<br>
          customers_scaled = scaler.fit_transform(customers)<br>
          <br>
          # Apply K-means clustering<br>
          kmeans = KMeans(n_clusters=4, random_state=42)<br>
          customer_segments = kmeans.fit_predict(customers_scaled)<br>
          <br>
          # Add cluster labels to dataframe<br>
          customers['Segment'] = customer_segments<br>
          <br>
          print("\\n=== CUSTOMER SEGMENTS ===")<br>
          for segment in range(4):<br>
          &nbsp;&nbsp;segment_data = customers[customers['Segment'] == segment]<br>
          &nbsp;&nbsp;print(f"\\nSegment {segment}: {len(segment_data)} customers")<br>
          &nbsp;&nbsp;print(f"  Avg Age: {segment_data['Age'].mean():.1f}")<br>
          &nbsp;&nbsp;print(f"  Avg Income: ${segment_data['Income'].mean():,.0f}")<br>
          &nbsp;&nbsp;print(f"  Avg Spending: {segment_data['SpendingScore'].mean():.1f}")<br>
          <br>
          print("\\n=== OTHER APPLICATIONS ===")<br>
          applications = {<br>
          &nbsp;&nbsp;"Healthcare": "Patient risk stratification, disease subtypes",<br>
          &nbsp;&nbsp;"Marketing": "Campaign targeting, product positioning",<br>
          &nbsp;&nbsp;"Biology": "Gene expression analysis, species classification",<br>
          &nbsp;&nbsp;"Image Processing": "Color quantization, object detection",<br>
          &nbsp;&nbsp;"Social Networks": "Community detection, influence analysis",<br>
          &nbsp;&nbsp;"Finance": "Portfolio optimization, fraud detection"<br>
          }<br>
          <br>
          for domain, use_cases
